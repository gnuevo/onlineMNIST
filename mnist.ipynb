{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST classification\n",
    "====================\n",
    "\n",
    "Simple classification of MNIST digits.\n",
    "\n",
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, BatchNormalization, UpSampling2D, Conv2D, LeakyReLU, Flatten, Softmax\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from random import shuffle, randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check wether we use GPU or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.0.0-alpha0\n",
      "We couldn't find your GPU\n"
     ]
    }
   ],
   "source": [
    "# print version and make sure we're using GPU\n",
    "print(\"Tensorflow version\", tf.__version__)\n",
    "if tf.test.is_gpu_available():\n",
    "    print(\"Congratulations, you're running on GPU!\")\n",
    "else:\n",
    "    print(\"We couldn't find your GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "print(type(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show some numbers to see what we can find in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'This is a 0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_number = randint(0, y_train.shape[0] - 1)\n",
    "plt.imshow(x_train[image_number,:,:], cmap=\"Greys\")\n",
    "plt.title(\"This is a {}\".format(y_train[image_number]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 28, 28, 1)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 22, 22, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 20, 20, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 18, 18, 32)        9248      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               1327232   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "softmax_2 (Softmax)          (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,370,442\n",
      "Trainable params: 1,370,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_mnist_classifier(input_shape=(28, 28)):\n",
    "    img = Input(shape=input_shape, dtype=\"float32\")\n",
    "    input_shape_with_channels = (*input_shape, 1)\n",
    "    x = Reshape(input_shape_with_channels)(img)\n",
    "#     x = tf.expand_dims(img, len(img.shape))\n",
    "    print(x.shape)\n",
    "    \n",
    "    # conv layers\n",
    "    x = Conv2D(16, (3, 3), padding=\"valid\", activation=\"relu\")(x)\n",
    "    x = Conv2D(32, (3, 3), padding=\"valid\", activation=\"relu\")(x)\n",
    "    x = Conv2D(32, (3, 3), padding=\"valid\", activation=\"relu\")(x)\n",
    "    x = Conv2D(32, (3, 3), padding=\"valid\", activation=\"relu\")(x)\n",
    "    x = Conv2D(32, (3, 3), padding=\"valid\", activation=\"relu\")(x)\n",
    "    \n",
    "    # dense layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128)(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = Dense(32)(x)\n",
    "    x = Dense(10)(x)\n",
    "    out = Softmax()(x)\n",
    "    \n",
    "    # build model\n",
    "    model = Model(inputs=[img], outputs=[out])\n",
    "    \n",
    "    return model\n",
    "\n",
    "build_mnist_classifier().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    optimizer = Adam()\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                 loss='sparse_categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "model = build_mnist_classifier()\n",
    "model = compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 65s 1ms/sample - loss: 0.1209 - accuracy: 0.9636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f49a805fef0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 240us/sample - loss: 0.0690 - accuracy: 0.9770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06902406927474077, 0.977]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 22, 22, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 20, 20, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 18, 18, 32)        9248      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               1327232   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "softmax_1 (Softmax)          (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,370,442\n",
      "Trainable params: 1,370,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('hola.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model, \"mnist_model.h5\", include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.0-alpha",
   "language": "python",
   "name": "tensorflow-2.0-alpha"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
